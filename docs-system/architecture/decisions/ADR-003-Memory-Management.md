# ADR-003: Advanced Memory Management System

## Status

Accepted

## Context

The current Bolt DIY system suffers from limitations in its memory management, leading to:

1. Context loss in longer conversations
2. Hallucinations due to missing or incorrect context
3. Inefficient use of context windows in LLM requests
4. Inability to retrieve relevant past interactions
5. Poor performance under load due to memory management inefficiencies

These issues impact the quality of AI interactions and overall system reliability.

## Decision

We will implement an advanced memory management system with the following components:

1. A hybrid architecture combining short-term buffer and long-term vector storage
2. Semantic search capabilities to retrieve relevant past interactions
3. Automatic summarization of older interactions to save context space
4. Configurable memory capacity and retention policies
5. Session-based memory isolation

## Consequences

### Positive

- Improved conversation coherence through better context retention
- Reduced hallucinations with more accurate memory retrieval
- More efficient use of LLM context windows
- Ability to reference information from much earlier in conversations
- Better scaling for long-running sessions

### Negative

- Increased system complexity
- Additional computational overhead for vector embeddings and search
- Potential latency from semantic retrieval operations
- Cost implications for vector database storage

## Implementation Notes

The memory system will consist of:

1. **Short-Term Buffer**: Fixed-size queue of recent interactions per session
2. **Long-Term Vector Store**: Persistent storage using embeddings for semantic search
3. **Summarization Engine**: LLM-based compression of older interactions
4. **Memory Retrieval**: Context-aware retrieval based on current query relevance
5. **Memory Manager**: Orchestrates these components and exposes a clean interface

The system will use a RAG (Retrieval-Augmented Generation) approach to enhance LLM responses.

## Example

```typescript
export class AdvancedMemoryManager implements IMemoryManager {
  constructor(
    private vectorStore: IVectorStore,
    private embeddingService: IEmbeddingService,
    private summarizationService: ISummarizationService,
    private config: MemoryConfig
  ) {}

  // Short-term memory maps session ID to a fixed-size queue
  private shortTermMemory: Map<string, CircularBuffer<Interaction>> = new Map();

  async getContext(sessionId: string, query: string): Promise<MemoryContext> {
    // Get short-term memory (recent interactions)
    const shortTerm = this.getShortTermMemory(sessionId);
    
    // Get relevant long-term memories through semantic search
    const embedding = await this.embeddingService.createEmbedding(query);
    const relevantMemories = await this.vectorStore.search(
      sessionId,
      embedding,
      this.config.retrievalCount
    );
    
    return {
      recentInteractions: shortTerm,
      relevantMemories: relevantMemories
    };
  }

  async storeInteraction(sessionId: string, interaction: Interaction): Promise<void> {
    // Store in short-term memory
    this.addToShortTermMemory(sessionId, interaction);
    
    // Store in long-term memory with embeddings
    const embedding = await this.embeddingService.createEmbedding(
      interaction.input + " " + interaction.response
    );
    
    await this.vectorStore.store(sessionId, interaction, embedding);
    
    // Check if summarization is needed
    await this.checkAndPerformSummarization(sessionId);
  }

  private addToShortTermMemory(sessionId: string, interaction: Interaction): void {
    // Implementation details for short-term storage
  }

  private async checkAndPerformSummarization(sessionId: string): Promise<void> {
    // Logic to decide when summarization is needed and perform it
  }
}
```